{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06906837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_supplier_vendor_name(text: str):\n",
    "    \"\"\"\n",
    "    Detect a supplier/vendor name in free-form text.\n",
    "    Handles:\n",
    "        - \"supplier ABC Corporation\"\n",
    "        - \"vendor XYZ Ltd\"\n",
    "        - \"from Acme Industries\"\n",
    "        - \"shipper Global Logistics\"\n",
    "    Returns the extracted name (cleaned and title-cased) or None.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    patterns = [\n",
    "        r\"supplier\\s+(?:name\\s+)?(?:is\\s+)?([A-Za-z0-9\\s\\.,&\\-']+?)(?:\\s+(?:for|with|has|is|on|in|at|,)|$)\",\n",
    "        r\"vendor\\s+(?:name\\s+)?(?:is\\s+)?([A-Za-z0-9\\s\\.,&\\-']+?)(?:\\s+(?:for|with|has|is|on|in|at|,)|$)\",\n",
    "        r\"from\\s+(?:supplier\\s+)?(?:vendor\\s+)?([A-Za-z0-9\\s\\.,&\\-']+?)(?:\\s+(?:for|with|has|is|on|in|at|,)|$)\",\n",
    "        r\"shipper\\s+(?:name\\s+)?(?:is\\s+)?([A-Za-z0-9\\s\\.,&\\-']+?)(?:\\s+(?:for|with|has|is|on|in|at|,)|$)\",\n",
    "    ]\n",
    "    \n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            # Extract and clean the name\n",
    "            name = m.group(1).strip()\n",
    "            # Remove trailing punctuation\n",
    "            name = re.sub(r'[,.\\s]+$', '', name)\n",
    "            # Clean up extra whitespace\n",
    "            name = re.sub(r'\\s+', ' ', name)\n",
    "            # Return if valid length (at least 2 characters)\n",
    "            if len(name) >= 2:\n",
    "                return name.title()\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07eb8400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(extract_supplier_vendor_name(\"QUEST COMPOSITE TECHNOLOGY\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564be77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_supplier_vendor_name(text: str):\n",
    "    \"\"\"\n",
    "    Detect a supplier/vendor name in free-form text.\n",
    "    Handles:\n",
    "        - \"supplier ABC Corporation\"\n",
    "        - \"vendor XYZ Ltd\"\n",
    "        - \"from Acme Industries\"\n",
    "        - \"shipper Global Logistics\"\n",
    "        - \"supplier QUEST COMPOSITE TECHNOLOGY(0026071)\"\n",
    "    Returns the extracted name (cleaned and title-cased) or None.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    patterns = [\n",
    "        r\"supplier\\s+(?:name\\s+)?(?:is\\s+)?([A-Za-z0-9\\s\\.,&\\-'()]+?)(?:\\s+(?:for|with|has|on|in|at)\\b|$)\",\n",
    "        r\"vendor\\s+(?:name\\s+)?(?:is\\s+)?([A-Za-z0-9\\s\\.,&\\-'()]+?)(?:\\s+(?:for|with|has|on|in|at)\\b|$)\",\n",
    "        r\"from\\s+(?:supplier\\s+)?(?:vendor\\s+)?([A-Za-z0-9\\s\\.,&\\-'()]+?)(?:\\s+(?:for|with|has|on|in|at)\\b|$)\",\n",
    "        r\"shipper\\s+(?:name\\s+)?(?:is\\s+)?([A-Za-z0-9\\s\\.,&\\-'()]+?)(?:\\s+(?:for|with|has|on|in|at)\\b|$)\",\n",
    "    ]\n",
    "    \n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            # Extract and clean the name\n",
    "            name = m.group(1).strip()\n",
    "            # Remove trailing punctuation (but keep parentheses if they're part of the name)\n",
    "            name = re.sub(r'[,.\\s]+$', '', name)\n",
    "            # Clean up extra whitespace\n",
    "            name = re.sub(r'\\s+', ' ', name)\n",
    "            # Return if valid length (at least 2 characters)\n",
    "            if len(name) >= 2:\n",
    "                return name.title()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dba5725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(extract_supplier_vendor_name(\"QUEST COMPOSITE TECHNOLOGY(0026071)\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16df04ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quest Composite Technology(0026071)\n"
     ]
    }
   ],
   "source": [
    "print(extract_supplier_vendor_name(\"supplier QUEST COMPOSITE TECHNOLOGY(0026071)\"))\n",
    "# Output: Quest Composite Technology(0026071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bc6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from config import settings\n",
    "\n",
    "def get_azure_embeddings() -> AzureOpenAIEmbeddings:\n",
    "    \"\"\"Return the Azure embeddings model – used by vectorstore and RAG.\"\"\"\n",
    "    return AzureOpenAIEmbeddings(\n",
    "        azure_deployment=settings.AZURE_OPENAI_EMBEDDING_MODEL,\n",
    "        openai_api_version=settings.AZURE_OPENAI_API_VERSION,\n",
    "        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=settings.AZURE_OPENAI_API_KEY,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0402d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=get_azure_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4508313",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"This is a test sequence for the embeddings model.\"\n",
    "vector = embeddings.embed_query(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cf79a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embedding successful!\n",
      "Vector dimension: 1536\n",
      "First 5 values: [-0.029504351815876323, -0.0025313085636933176, -0.004927523671912916, -0.0015375293312978294, 0.014279349046610776]\n",
      "Vector type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"✓ Embedding successful!\")\n",
    "print(f\"Vector dimension: {len(vector)}\")\n",
    "print(f\"First 5 values: {vector[:5]}\")\n",
    "print(f\"Vector type: {type(vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe9d816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch embedding successful!\n",
      "Number of documents embedded: 3\n",
      "Each vector dimension: 1536\n",
      "First 5 values of the first vector: [-0.0009257371044195405, -0.036719217294288044, 0.00021014569543001887, 0.00040595848073678625, -0.020180731865602163]\n",
      "Vector type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Test batch embeddings\n",
    "test_documents = [\n",
    "    \"Container shipment delayed\",\n",
    "    \"Supplier delivery on time\",\n",
    "    \"Cargo inspection complete\"\n",
    "]\n",
    "vectors = embeddings.embed_documents(test_documents)\n",
    "\n",
    "print(f\"✓ Batch embedding successful!\")\n",
    "print(f\"Number of documents embedded: {len(vectors)}\")\n",
    "print(f\"Each vector dimension: {len(vectors[0])}\")\n",
    "print(f\"First 5 values of the first vector: {vectors[0][:5]}\")\n",
    "print(f\"Vector type: {type(vectors[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98ef473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# services/vectorstore.py\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "from config import settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab555e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from config import settings\n",
    "from services.azure_blob import get_shipment_df\n",
    "\n",
    "logger = logging.getLogger(\"shipping_chatbot\")\n",
    "VECTORSTORE_DIR = Path(\"faiss_index\")\n",
    "\n",
    "\n",
    "def _embeddings() -> AzureOpenAIEmbeddings:\n",
    "    \"\"\"Create AzureOpenAIEmbeddings the same object used for RAG and for the RetrievalQA chain.\"\"\"\n",
    "    return AzureOpenAIEmbeddings(\n",
    "        azure_deployment=settings.AZURE_OPENAI_EMBEDDING_MODEL,\n",
    "        openai_api_version=settings.AZURE_OPENAI_API_VERSION,\n",
    "        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=settings.AZURE_OPENAI_API_KEY,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de1b2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_index() -> FAISS:\n",
    "    \"\"\"\n",
    "    Build a brand new FAISS index from the shipment dataframe.\n",
    "    The routine is batched (50 docs per batch) and respects Azure rate limits.\n",
    "    \"\"\"\n",
    "    logger.info(\"Creating new FAISS vector store\")\n",
    "    df = get_shipment_df()\n",
    "\n",
    "    # Turn each row into a single text block\n",
    "    # Optimization: Use a format that is more token-efficient or LLM-friendly if possible.\n",
    "    # Logic Fix: Increase text chunk size to avoid splitting a single row into multiple incoherent chunks.\n",
    "    rows_as_text = [\n",
    "        \"\\n\".join(f\"{k}: {v}\" for k, v in row.items() if str(v).strip())\n",
    "        for row in df.fillna(\"\").astype(str).to_dict(orient=\"records\")\n",
    "    ]\n",
    "\n",
    "    # CRITICAL FIX: Increased chunk_size from 400 to 2000.\n",
    "    # Splitting a row breaks the context (e.g. key 'ETA' separated from value).\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    chunks: List[str] = []\n",
    "\n",
    "    # Check if rows are effectively split. Ideally, we want 1 row = 1 chunk.\n",
    "    for txt in rows_as_text:\n",
    "        # If the row is small enough, keep it as is.\n",
    "        # split_text will return [txt] if it fits.\n",
    "        split_chunks = splitter.split_text(txt)\n",
    "        chunks.extend(split_chunks)\n",
    "\n",
    "    embeddings = _embeddings()\n",
    "\n",
    "    # Optimization: Increase batch size slightly if Azure permits (usually safe up to 16k tokens/req).\n",
    "    # 50 rows * 500 chars ~= 25k chars ~= 6k tokens. Safe.\n",
    "    batch = 50\n",
    "    vectorstore = FAISS.from_texts(chunks[:batch], embeddings)\n",
    "\n",
    "    for i in range(batch, len(chunks), batch):\n",
    "        vectorstore.add_texts(chunks[i : i + batch])\n",
    "        if i % (batch * 5) == 0:\n",
    "            logger.debug(f\"Indexed batch {i // batch + 1}/{len(chunks)//batch}\")\n",
    "\n",
    "        # 0.2s should be sufficient.\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    VECTORSTORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    vectorstore.save_local(str(VECTORSTORE_DIR))\n",
    "    logger.info(\"FAISS index persisted\")\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Public accessor – lazy‑load on first call\n",
    "# ----------------------------------------------------------------------\n",
    "_vectorstore: FAISS | None = None\n",
    "\n",
    "\n",
    "def get_vectorstore() -> FAISS:\n",
    "    \"\"\"Return a cached FAISS store; builds it on first request.\"\"\"\n",
    "    global _vectorstore\n",
    "    if _vectorstore is None:\n",
    "        if VECTORSTORE_DIR.exists():\n",
    "            logger.info(\"Loading existing FAISS index\")\n",
    "            try:\n",
    "                _vectorstore = FAISS.load_local(\n",
    "                    str(VECTORSTORE_DIR),\n",
    "                    _embeddings(),\n",
    "                    allow_dangerous_deserialization=True,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to load existing index: {e}. Rebuilding...\")\n",
    "                _vectorstore = _build_index()\n",
    "        else:\n",
    "            _vectorstore = _build_index()\n",
    "    return _vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9051c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfe83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef8d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
